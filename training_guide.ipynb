{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30684fe3",
   "metadata": {},
   "source": [
    "# TRAIN YOUR OWN CUSTOM OBJECT DETECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42fff4c",
   "metadata": {},
   "source": [
    "# 1. Create a new directory for training\n",
    "\n",
    "## Directory Tree\n",
    "\n",
    "- home/\n",
    "    - models/\n",
    "    - proto/\n",
    "    - workspace/\n",
    "        - Dockerfile\n",
    "        - scripts/\n",
    "            - image_downloader.py\n",
    "            - xml_to_csv.py\n",
    "            - create_tfrecords.py\n",
    "        - training-directory/\n",
    "            - annotations/\n",
    "            - custom-models/\n",
    "            - exported-models/\n",
    "            - images/\n",
    "                - test/\n",
    "                - train/\n",
    "            - pretrained-models/\n",
    "\n",
    "***\n",
    "\n",
    "- annotations/ - store the label map file(.pbtxt), the csv file (.csv) and corresponding TFRecord file (.record)\n",
    "***\n",
    "- images/ - copy of all the images (.jpg) in the dataset with corresponding xml files (.xml). image and xml files are created by a labelling software such as labelImg\n",
    "***\n",
    "- images/train/ - a copy of all the image and the corresponding xml files for training the model\n",
    "***\n",
    "- images/test/ - a copy of all the image and the corresponding xml files for testing the model\n",
    "***\n",
    "- custom-models/ - contains a sub directory for each of training job. Each subfolder will contain the training pipeline configuration file (.config) and other files generated during the training and evaluation of the model.\n",
    "***\n",
    "- pretrained-models/ - contains the downloaded pretrained models that will be used as a starting checkpoint to train the jobs. aka transfer learning.\n",
    "***\n",
    "- exported-models/ - store the exported version of the trained detector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working directory\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# training directory name\n",
    "training_directory = \"training-bear-SSD-MobileNet-V2-FPNLite-320x320\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list that contains the classes\n",
    "labels = [\n",
    "    \"bear\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c191a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to be created inside the training directory\n",
    "PATHS = {\n",
    "    \"training\": \"{}/{}\".format(cwd, training_directory),\n",
    "    \"annotations\": \"{}/{}/annotations\".format(cwd, training_directory),\n",
    "    \"custom-models\": \"{}/{}/custom-models\".format(cwd, training_directory),\n",
    "    \"exported-models\": \"{}/{}/exported-models\".format(cwd, training_directory),\n",
    "    \"images\": \"{}/{}/images\".format(cwd, training_directory),\n",
    "    \"train-images\": \"{}/{}/images/train-images\".format(cwd, training_directory),\n",
    "    \"test-images\": \"{}/{}/images/test-images\".format(cwd, training_directory),\n",
    "    \"validation-images\": \"{}/{}/images/validation-images\".format(cwd, training_directory),\n",
    "    \"pretrained-models\": \"{}/{}/pretrained-models\".format(cwd, training_directory)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the paths for each class to store train and test images\n",
    "for label in labels:\n",
    "    PATHS[\"{}-images\".format(label)] = \"{}/{}-images\".format(PATHS[\"images\"], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd56725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the paths if they are not existing!\n",
    "\n",
    "for path in PATHS.values():\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97253ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the directories inside PATHS have been created!\n",
    "!ls {PATHS[\"training\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dbbb05",
   "metadata": {},
   "source": [
    "# 2. Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32977a8",
   "metadata": {},
   "source": [
    "## 2.1. Gather images\n",
    "- image_downloader.py is a tool to install several images from google images\n",
    "***\n",
    "- -c   chromedriver path\n",
    "***\n",
    "- -k   keyword to search for images on google images\n",
    "***\n",
    "- -o   output path to write all the installed images\n",
    "***\n",
    "- -l   specify a level for the amount of images installed. Must be an integer, ranging from 1 to 5. The more the level is the more the amount of images to be installed.\n",
    "***\n",
    "- Or gather images from public datasets/databases, such as __[Open Images](https://storage.googleapis.com/openimages/web/index.html)__ and put those gathered images into the images folder for the corresponding object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_downloader.py needs chromedriver, therefore find the executable path! \n",
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the python script image_downloader.py\n",
    "!ls scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c037c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact path to the image_downloader.py script\n",
    "!cd scripts && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab518dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this script to install images for each label\n",
    "!python3 /home/workspace/scripts/image_downloader.py \\\n",
    "    -c /usr/local/bin/chromedriver \\\n",
    "    -k bear \\\n",
    "    -o {PATHS[\"bear-images\"]} \\\n",
    "    -l 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344862e",
   "metadata": {},
   "source": [
    "## 2.2 Annotate data\n",
    "- Go and get __[labelImg](https://github.com/tzutalin/labelImg)__ and run labelImg.py, if you encounter a problem like not being able to write to a file then run labelImg.py with sudo.\n",
    "***\n",
    "- Open your images directory e.g. \"home/workspace/training-dir/images\" and start annotating the images inside of that folder.\n",
    "***\n",
    "- once you are done with annotating your images, in the images folder you should have an image file(.jpg) and an xml file(.xml) for each image that images directory.\n",
    "***\n",
    "- Do not create an xml file for the images that you do not wish to use for the training or testing. Next section will deal to delete those from the images directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020d6a1",
   "metadata": {},
   "source": [
    "## 2.3. Delete unused images\n",
    "\n",
    "- If an image is not annotated, then it does not have a corresponding xml file. Delete those images which are not labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_to_remove(path):\n",
    "    # get all the image, jpg files\n",
    "    jpg_files = [file[:-4:1] for file in os.listdir(path) if file[-4::1] == \".jpg\"]\n",
    "    \n",
    "    # get all the xml files, PASCAL VOC\n",
    "    xml_files = [file[:-4:1] for file in os.listdir(path) if file[-4::1] == \".xml\"]\n",
    "    \n",
    "    # compare if the jpg file has a corresponding xml file, otherwise append to the list\n",
    "    jpg_files_to_remove = [jpg_file + \".jpg\" for jpg_file in jpg_files if jpg_file not in xml_files]\n",
    "    \n",
    "    print(\"Number of total gathered images: {}\".format(str(len(jpg_files))))\n",
    "    print(\"Number of selected images: {}\".format(str(len(xml_files))))\n",
    "    print(\"Number of images to be removed: {}\".format(str(len(jpg_files_to_remove))))\n",
    "    \n",
    "    return jpg_files_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea73756",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = {}\n",
    "\n",
    "# loop through labels array to get the images that will be removed\n",
    "# for each label class\n",
    "\n",
    "for label in labels:\n",
    "    print(\"Getting the images to be removed for {}\".format(label))\n",
    "    files_to_remove[label] = get_images_to_remove(PATHS[\"{}-images\".format(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6404613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each label and remove the images to be removed\n",
    "\n",
    "for label, files in files_to_remove.items():\n",
    "    path = PATHS[\"{}-images\".format(label)]\n",
    "    print(\"removing the unused images from {} folder\".format(path))\n",
    "    print(len(files))\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a5200",
   "metadata": {},
   "source": [
    "## 2.4. Split data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa03bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_training_testing_data(files_path, training_percentage = 85, validation_percentage = 10):\n",
    "    training_percentage = float(training_percentage)\n",
    "    validation_percentage = float(validation_percentage)\n",
    "    \n",
    "    num_of_training_data = (len(files_path) * training_percentage) // 100\n",
    "    num_of_validation_data = (len(files_path) * validation_percentage) // 100\n",
    "    \n",
    "    training_data = random.sample(files_path,int(num_of_training_data))\n",
    "    testing_and_validation_data = [e for e in files_path if e not in training_data]\n",
    "    \n",
    "    validation_data = random.sample(testing_and_validation_data,int(num_of_validation_data))\n",
    "    \n",
    "    testing_data = [e for e in testing_and_validation_data if e not in validation_data]\n",
    "    \n",
    "    return training_data, validation_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72caf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "\n",
    "for label in labels:\n",
    "    path = PATHS[\"{}-images\".format(label)]\n",
    "    # get all the xml files inside of that path\n",
    "    xml_files = glob.glob(path + \"/*.xml\")\n",
    "    file_paths = [file.replace(\".xml\", \"\") for file in xml_files]\n",
    "    \n",
    "    training_file_paths, validation_file_paths, testing_file_paths = get_training_testing_data(file_paths, 85, 10)\n",
    "    \n",
    "    # copy jpg and xml file for each image to training folder\n",
    "    for file_path in training_file_paths:\n",
    "        # copy jpg file\n",
    "        shutil.copy(file_path + \".jpg\", PATHS[\"train-images\"])\n",
    "        # copy xml file\n",
    "        shutil.copy(file_path + \".xml\", PATHS[\"train-images\"])\n",
    "    \n",
    "    # copy jpg and xml file for each image to evaluation folder\n",
    "    for file_path in validation_file_paths:\n",
    "        # copy jpg file\n",
    "        shutil.copy(file_path + \".jpg\", PATHS[\"validation-images\"])\n",
    "        # copy xml file\n",
    "        shutil.copy(file_path + \".xml\", PATHS[\"validation-images\"])\n",
    "    \n",
    "    # copy jpg and xml file for each image to test folder\n",
    "    for file_path in testing_file_paths:\n",
    "        # copy jpg file\n",
    "        shutil.copy(file_path + \".jpg\", PATHS[\"test-images\"])\n",
    "        # copy xml file\n",
    "        shutil.copy(file_path + \".xml\", PATHS[\"test-images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3296f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"train-images\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"validation-images\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"test-images\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b63ce",
   "metadata": {},
   "source": [
    "## 2.5. Create Label map file\n",
    "\n",
    "- TensorFlow needs a label map file (.pbtxt)\n",
    "- A labelmap file maps each of the used labels to an integer values.\n",
    "- This label map is used both by the training and detection processes.\n",
    "- Add your labels into the labels list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a label map file under annotations\n",
    "!touch {PATHS[\"annotations\"]}/label_map.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"annotations\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06428878",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_file = os.path.join(PATHS[\"annotations\"], \"label_map.pbtxt\")\n",
    "\n",
    "labelmaps = [None] * len(labels)\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    labelmaps[idx] = {\"name\": label, \"id\": idx + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460707bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18201cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(label_map_file, \"w\") as f:\n",
    "    for labelmap in labelmaps:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(labelmap['name']))\n",
    "        f.write('\\tid:{}\\n'.format(labelmap['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {PATHS[\"annotations\"]}/label_map.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d098d64",
   "metadata": {},
   "source": [
    "## 2.6. Create TensorFlow Records\n",
    "\n",
    "- Convert xml annotations to TFRecord format (.record).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330418c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ab4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd scripts && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_to_csv_path = \"/home/workspace/scripts/xml_to_csv.py\"\n",
    "create_tfrecords_path = \"/home/workspace/scripts/create_tfrecords.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train.csv file in annotations folder\n",
    "# run xml_to_csv.py to create a csv file for training data\n",
    "!python3 {xml_to_csv_path} \\\n",
    "    -p {PATHS[\"train-images\"]} \\\n",
    "    -o {PATHS[\"annotations\"]}/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {PATHS[\"annotations\"]}/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b10d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evaluation.csv file in annotations folder\n",
    "# run xml_to_csv.py to create a csv file for evaluation data\n",
    "!python3 {xml_to_csv_path} \\\n",
    "    -p {PATHS[\"validation-images\"]} \\\n",
    "    -o {PATHS[\"annotations\"]}/validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b45f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {PATHS[\"annotations\"]}/validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7934ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test.csv file in annotations folder\n",
    "# run xml_to_csv.py to create a csv file for test data\n",
    "!python3 {xml_to_csv_path} \\\n",
    "    -p {PATHS[\"test-images\"]} \\\n",
    "    -o {PATHS[\"annotations\"]}/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d639063",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {PATHS[\"annotations\"]}/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59904ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train.record under annotations folder\n",
    "# run create_tfrecords.py to create a tfrecord file from the csv file\n",
    "!python3 {create_tfrecords_path} \\\n",
    "    -l {PATHS[\"annotations\"]}/label_map.pbtxt \\\n",
    "    -o {PATHS[\"annotations\"]}/train.record \\\n",
    "    -i {PATHS[\"train-images\"]} \\\n",
    "    -c {PATHS[\"annotations\"]}/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evaluation.record under annotations folder\n",
    "# run create_tfrecords.py to create a tfrecord file from the csv file\n",
    "!python3 {create_tfrecords_path} \\\n",
    "    -l {PATHS[\"annotations\"]}/label_map.pbtxt \\\n",
    "    -o {PATHS[\"annotations\"]}/validation.record \\\n",
    "    -i {PATHS[\"validation-images\"]} \\\n",
    "    -c {PATHS[\"annotations\"]}/validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test.record under annotations folder\n",
    "# run create_tfrecords.py to create a tfrecord file from the csv file\n",
    "!python3 {create_tfrecords_path} \\\n",
    "    -l {PATHS[\"annotations\"]}/label_map.pbtxt \\\n",
    "    -o {PATHS[\"annotations\"]}/test.record \\\n",
    "    -i {PATHS[\"test-images\"]} \\\n",
    "    -c {PATHS[\"annotations\"]}/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf59496",
   "metadata": {},
   "source": [
    "# 3. Fine-tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0668908",
   "metadata": {},
   "source": [
    "## 3.1. Selection of the pretrained object detection model\n",
    "- TensorFlow Object Detection API provides several pretrained models under __[TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)__.\n",
    "- Those models are trained with COCO dataset and can detect about 80 objects.\n",
    "- Visit __[here](https://cocodataset.org/#home)__ to learn more about COCO dataset.\n",
    "- All the models are trained using the same data but have different architecture, therefore, each model has its own corresponding speed, COCO mAP(Mean Average Precision).\n",
    "- go to __[TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)__ and choose your model.\n",
    "\n",
    "- This notebook is using \"SSD MobileNet V2 FPNLite 320x320\", change pretrained_model_url for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4013ed",
   "metadata": {},
   "source": [
    "### Download the latest pretrained network for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c371aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL UNDER {PATHS[\"pretrained-models\"]}\n",
    "!wget -P {PATHS[\"pretrained-models\"]} \\\n",
    "    {pretrained_model_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8065fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the name of the installed tar\n",
    "!ls {PATHS[\"pretrained-models\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_folder_name = \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNZIP THE TAR\n",
    "!tar -xvf {PATHS[\"pretrained-models\"]}/{tar_folder_name} \\\n",
    "    -C {PATHS[\"pretrained-models\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"pretrained-models\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE THE TAR\n",
    "!rm -r {PATHS[\"pretrained-models\"]}/{tar_folder_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"pretrained-models\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD THE RECENTLY INSTALLED PRETRAINED MODEL PATH TO THE PATHS DICTIONARY, c\n",
    "PATHS[\"my-pretrained-model\"] = PATHS[\"pretrained-models\"] + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bfdc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"my-pretrained-model\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CUSTOM MODEL PATH TO THE PATHS DICTIONARY\n",
    "PATHS[\"my-custom-model\"] = PATHS[\"custom-models\"] + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cffa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS[\"my-custom-model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DIRECTORY FOR YOUR CUSTOM MODEL\n",
    "!mkdir {PATHS[\"my-custom-model\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02963064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pipeline config file from the pretrained model to the new folder\n",
    "!cp {PATHS[\"my-pretrained-model\"]}/pipeline.config \\\n",
    "    {PATHS[\"my-custom-model\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"my-custom-model\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074208d",
   "metadata": {},
   "source": [
    "## 3.2. Configure the training pipeline\n",
    "\n",
    "### Some of the important attributes\n",
    "1. model.ssd.num_classes: number of classes\n",
    "2. train_config.batch_size: Increase/Decrease this value depending on the available memory (Higher values require more memory and vice-versa) (e.g. 4)\n",
    "3. train_config.fine_tune_checkpoint: Path to checkpoint of pre-trained model. (e.g. pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\")\n",
    "4. train_config.fine_tune_checkpoint_type: Set this to \"detection\" if you are going to be training the model for detection\n",
    "5. train_config.use_bfloat16: Set this to false if you are not training on a TPU\n",
    "6. train_input_reader.label_map_path: Path to label map file. (e.g. annotations/label_map.pbtxt)\n",
    "7. train_input_reader.tf_record_input_reader.input_path: Path to training TFRecord file (e.g. annotations/train.record)\n",
    "8. eval_input_reader.label_map_path: Path to label map file (e.g. annotations/label_map.pbtxt)\n",
    "9. eval_input_reader.tf_record_input_reader.input_path: Path to testing TFRecord (e.g. annotations/evalation.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc93c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS[\"my-pretrained-model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"my-pretrained-model\"]}/checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS[\"annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c42b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"annotations\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3768a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {PATHS[\"my-custom-model\"]}/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ba423",
   "metadata": {},
   "source": [
    "### Now open the pipeline.config file that is inside the custom model directory and edit it manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ffa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.config after configuration\n",
    "!cat {PATHS[\"my-custom-model\"]}/pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48dd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && cd models/research/object_detection && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY model_main_tf2.py FILE TO THE TRAINING DIRECTORY\n",
    "!cp /home/models/research/object_detection/model_main_tf2.py {PATHS[\"training\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"training\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"custom-models\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480938bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"my-custom-model\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb861220",
   "metadata": {},
   "source": [
    "## 3.3. Start transfer learning\n",
    "Run the training command from a terminal rather than running on this notebook. For that if you are on Linux go ahead and open up a new terminal and connect to that running docker container by following the steps below\n",
    "<br>\n",
    "<br>\n",
    "1. get the id of the running container by inspecting the output of:\n",
    "- docker ps\n",
    "2. connect to that running docker container by executing(replace container_id with the running container's id):\n",
    "- docker exec -i -t container_id bash\n",
    "3. run the training command in a terminal, and run the validation command in another terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the command if you want to run the training command on terminal\n",
    "pipeline_config_path = os.path.join(PATHS[\"my-custom-model\"], \"pipeline.config\")\n",
    "num_of_steps_per_checkpoint = 500\n",
    "\n",
    "# training command\n",
    "train_command = \"cd {} && python3 model_main_tf2.py --model_dir={} --pipeline_config_path={} --checkpoint_every_n={}\".format(PATHS[\"training\"], PATHS[\"my-custom-model\"], pipeline_config_path, int(num_of_steps_per_checkpoint))\n",
    "\n",
    "# validation command\n",
    "validation_command = \"cd {} && python3 model_main_tf2.py --model_dir={} --pipeline_config_path={} --checkpoint_dir={} --sample_1_of_n_eval_examples=1\".format(PATHS[\"training\"], PATHS[\"my-custom-model\"], pipeline_config_path, PATHS[\"my-custom-model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b814a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the training is done\n",
    "# CUSTOM MODEL PATH SHOULD HAVE CHECKPOINTS, PIPELINE CONFIG, AND A TRAIN FOLDER\n",
    "!ls {PATHS[\"MY_CUSTOM_MODEL\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f979ff0",
   "metadata": {},
   "source": [
    "### Monitoring the training job progress using TensorBoard\n",
    "\n",
    "__[TensorBoard](https://www.tensorflow.org/tensorboard)__ allows you to coninuously monitor and visualise a number of different training/evaluation metrics, while your model is being trained.\n",
    "<br>\n",
    "<br>\n",
    "1. Before starting a TensorBoard server, go ahead and connect to that running docker container from a different terminal by following the steps provided in the third section. Also make sure when you are running the docker container you bind at least 2 ports for the docker container, one for the jupyter notebook and another for the TensorBoard. You can also check available ports for that running container by inspecting:\n",
    "- docker ps\n",
    "<br>\n",
    "<br>\n",
    "2. Once you are connected to that running container start a new TensorBoard server by running:\n",
    "- tensorboard --logdir=PATH_TO_MY_CUSTOM_MODEL --port=PORT --host 0.0.0.0\n",
    "<br>\n",
    "<br>\n",
    "3. Command will start a new TensorBoard server, listening on the specified PORT of the docker container.\n",
    "<br>\n",
    "<br>\n",
    "4. The command will output a url that you can use to go to the TensorBoard dashboard:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 6006\n",
    "tensorboard_command = \"{} --logdir={} --port={} --host 0.0.0.0\".format(\"tensorboard\", PATHS[\"my-custom-model\"], str(port))\n",
    "print(tensorboard_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27299256",
   "metadata": {},
   "source": [
    "# 4. Object detection from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b91d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"my-custom-model\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"annotations\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72394412",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### VARIABLES ###############\n",
    "pipeline_config_path = \"{}/pipeline.config\".format(PATHS[\"my-custom-model\"])\n",
    "labelmap_path = \"{}/label_map.pbtxt\".format(PATHS[\"annotations\"])\n",
    "# get the latest checkpoint\n",
    "checkpoint_file_path = \"{}/ckpt-11\".format(PATHS[\"my-custom-model\"])\n",
    "\n",
    "# build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "model_config = configs[\"model\"]\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# restore checkpoint\n",
    "checkpoint = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "checkpoint.restore(checkpoint_file_path).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(img_tensor):\n",
    "    img_tensor, shapes = detection_model.preprocess(img_tensor)\n",
    "    predictions = detection_model.predict(img_tensor, shapes)\n",
    "    detections = detection_model.postprocess(predictions, shapes)\n",
    "    return detections\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ececa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(img_path, result_file_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_arr = np.array(img)\n",
    "    \n",
    "    # convert numpy array to tensor\n",
    "    img_tensor = tf.convert_to_tensor(np.expand_dims(img_arr, 0), dtype=tf.float32)\n",
    "    \n",
    "    # get the objects in that tensor\n",
    "    detections = detect_fn(img_tensor)\n",
    "    \n",
    "    num_of_detections = int(detections.pop('num_detections'))\n",
    "    \n",
    "    detections = {key: value[0, :num_of_detections].numpy() for key, value in detections.items()}\n",
    "    \n",
    "    detections['num_detections'] = num_of_detections\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    label_id_offset = 1\n",
    "    img_arr_detections = img_arr.copy()\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        img_arr_detections,\n",
    "        detections[\"detection_boxes\"],\n",
    "        detections[\"detection_classes\"] + label_id_offset,\n",
    "        detections[\"detection_scores\"],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=.5,\n",
    "        min_score_thresh= 0.7,\n",
    "        agnostic_mode=False)\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(img_arr_detections, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(result_file_path, bbox_inches='tight',pad_inches = 0)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"test-images\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the jpg paths for testing from testing images\n",
    "import glob\n",
    "import random\n",
    "img_paths = sorted(glob.glob(PATHS[\"test-images\"] + \"/*.jpg\"))\n",
    "print(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ddac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"bear-images\"]}/bear-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to store the result jpg files\n",
    "PATHS[\"detection-results-1-11ckpt\"] = PATHS[\"images\"] + \"/detection-results-1-11ckpt\"\n",
    "!mkdir {PATHS[\"detection-results-1-11ckpt\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(img_paths):\n",
    "    detect(img, PATHS[\"detection-results-1-11ckpt\"] + \"/results-{}.jpg\".format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATHS[\"training\"]}/images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af3f03",
   "metadata": {},
   "source": [
    "# If you are not satisfy with the model continue training\n",
    "\n",
    "- to fine-tune the model use the latest checkpoint but create a new folder for the model.\n",
    "- keep the confugations as the same except the train_input_reader\n",
    "\n",
    "- change \"train_config.fine_tune_checkpoint\" to the latest checkpoint of the custom model. It was similar to \"/home/workspace/training-bear/pretrained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\". Now change ckpt-0 to the latest such as ckpt-11.\n",
    "- then start the training again using the training command\n",
    "\n",
    "- Simply keep using the same configuration (except the train_input_reader) with the same model_dir of your previous model. That way, the API will create a graph and will check whether a checkpoint already exists in model_dir and fits the graph. If so - it will restore it and continue training it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c48d64",
   "metadata": {},
   "source": [
    "# References and Further studies\n",
    "\n",
    "__[TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)__\n",
    "\n",
    "__[TensorFlow Model Garden](https://github.com/tensorflow/models)__\n",
    "\n",
    "__[TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)__\n",
    "\n",
    "__[TensorFlow 2 Object Detection API tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-label-map)__\n",
    "\n",
    "__[labelImg annotation tool](https://github.com/tzutalin/labelImg)__\n",
    "\n",
    "__[Object Detection from checkpoint](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/plot_object_detection_checkpoint.html)__\n",
    "\n",
    "__[COCO dataset](https://cocodataset.org/#home)__\n",
    "\n",
    "__[Object Detection From TF2 Saved Model](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/plot_object_detection_saved_model.html)__\n",
    "\n",
    "__[Object Detection From TF2 Checkpoint](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/plot_object_detection_checkpoint.html)__\n",
    "\n",
    "__[Detect Objects Using a Webcam](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/object_detection_camera.html)__\n",
    "\n",
    "__[Training and Evaluating Custom Object Detectors](https://becominghuman.ai/tensorflow-object-detection-api-tutorial-training-and-evaluating-custom-object-detector-ed2594afcf73)__\n",
    "\n",
    "__[TensorFlow Object Detection API: Best Practices to Training, Evaluation & Deployment](https://neptune.ai/blog/tensorflow-object-detection-api-best-practices-to-training-evaluation-deployment)__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
